{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2661/2555632222.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader, PDFMinerLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.document_loaders import DataFrameLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# на тестовом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = [\n",
    "#     {\"id\": \"1\", \"question\": \"Как восстановить пароль?\", \"answer\": \"Если вы забыли пароль, воспользуйтесь службой восстановления. В отправленном вам письме будет ссылка на смену пароля.\", 'url': \"\"},\n",
    "#     {\"id\": \"2\", \"question\": \"Как сменить логин?\", \"answer\": \"Логин изменить невозможно. Логин есть у тех пользователей, кто зарегистрировался на сайте до мая 2015 года. Участники, которые зарегистрировались позже, при авторизации вместо логина указывают свою электронную почту.\", \"url\": \"\"}\n",
    "# ]\n",
    "\n",
    "# # создаем из наших документов датафрейм\n",
    "# df = pd.DataFrame(documents)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# грузим фрейм в лоадер, выделив колонку для векторизации (здесь может быть место для дискуссий)\n",
    "df = pd.read_csv(\"./SOURCE_DOCUMENTS/questions_stolot.csv\", dtype='object')\n",
    "loader = DataFrameLoader(df, page_content_column='question')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_text_splitter = RecursiveCharacterTextSplitter(chunk_size=700,\n",
    "                                               chunk_overlap=700,\n",
    "                                               length_function=len\n",
    "                                               )\n",
    "texts = rec_text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">**=== chromadb ===**</span>\n",
    "В этой вариации я использую векторный поиск не по всему тексту, а по документам, в которых поиск выполняется только по полю \"question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "chroma_client = chromadb.HttpClient(settings=Settings(\n",
    "    allow_reset=True,\n",
    "    chroma_api_impl='chromadb.api.fastapi.FastAPI',\n",
    "    chroma_server_host='localhost',\n",
    "    chroma_server_http_port='8000')\n",
    ")\n",
    "chroma_client.delete_collection('book')\n",
    "collection = chroma_client.create_collection(name='book',\n",
    "                                             metadata={\"hnsw:space\": \"cosine\"},\n",
    "                                             embedding_function=embedding_function\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0.74%\n",
      "Done: 1.48%\n",
      "Done: 2.22%\n",
      "Done: 2.96%\n",
      "Done: 3.7%\n",
      "Done: 4.44%\n",
      "Done: 5.19%\n",
      "Done: 5.93%\n",
      "Done: 6.67%\n",
      "Done: 7.41%\n",
      "Done: 8.15%\n",
      "Done: 8.89%\n",
      "Done: 9.63%\n",
      "Done: 10.37%\n",
      "Done: 11.11%\n",
      "Done: 11.85%\n",
      "Done: 12.59%\n",
      "Done: 13.33%\n",
      "Done: 14.07%\n",
      "Done: 14.81%\n",
      "Done: 15.56%\n",
      "Done: 16.3%\n",
      "Done: 17.04%\n",
      "Done: 17.78%\n",
      "Done: 18.52%\n",
      "Done: 19.26%\n",
      "Done: 20.0%\n",
      "Done: 20.74%\n",
      "Done: 21.48%\n",
      "Done: 22.22%\n",
      "Done: 22.96%\n",
      "Done: 23.7%\n",
      "Done: 24.44%\n",
      "Done: 25.19%\n",
      "Done: 25.93%\n",
      "Done: 26.67%\n",
      "Done: 27.41%\n",
      "Done: 28.15%\n",
      "Done: 28.89%\n",
      "Done: 29.63%\n",
      "Done: 30.37%\n",
      "Done: 31.11%\n",
      "Done: 31.85%\n",
      "Done: 32.59%\n",
      "Done: 33.33%\n",
      "Done: 34.07%\n",
      "Done: 34.81%\n",
      "Done: 35.56%\n",
      "Done: 36.3%\n",
      "Done: 37.04%\n",
      "Done: 37.78%\n",
      "Done: 38.52%\n",
      "Done: 39.26%\n",
      "Done: 40.0%\n",
      "Done: 40.74%\n",
      "Done: 41.48%\n",
      "Done: 42.22%\n",
      "Done: 42.96%\n",
      "Done: 43.7%\n",
      "Done: 44.44%\n",
      "Done: 45.19%\n",
      "Done: 45.93%\n",
      "Done: 46.67%\n",
      "Done: 47.41%\n",
      "Done: 48.15%\n",
      "Done: 48.89%\n",
      "Done: 49.63%\n",
      "Done: 50.37%\n",
      "Done: 51.11%\n",
      "Done: 51.85%\n",
      "Done: 52.59%\n",
      "Done: 53.33%\n",
      "Done: 54.07%\n",
      "Done: 54.81%\n",
      "Done: 55.56%\n",
      "Done: 56.3%\n",
      "Done: 57.04%\n",
      "Done: 57.78%\n",
      "Done: 58.52%\n",
      "Done: 59.26%\n",
      "Done: 60.0%\n",
      "Done: 60.74%\n",
      "Done: 61.48%\n",
      "Done: 62.22%\n",
      "Done: 62.96%\n",
      "Done: 63.7%\n",
      "Done: 64.44%\n",
      "Done: 65.19%\n",
      "Done: 65.93%\n",
      "Done: 66.67%\n",
      "Done: 67.41%\n",
      "Done: 68.15%\n",
      "Done: 68.89%\n",
      "Done: 69.63%\n",
      "Done: 70.37%\n",
      "Done: 71.11%\n",
      "Done: 71.85%\n",
      "Done: 72.59%\n",
      "Done: 73.33%\n",
      "Done: 74.07%\n",
      "Done: 74.81%\n",
      "Done: 75.56%\n",
      "Done: 76.3%\n",
      "Done: 77.04%\n",
      "Done: 77.78%\n",
      "Done: 78.52%\n",
      "Done: 79.26%\n",
      "Done: 80.0%\n",
      "Done: 80.74%\n",
      "Done: 81.48%\n",
      "Done: 82.22%\n",
      "Done: 82.96%\n",
      "Done: 83.7%\n",
      "Done: 84.44%\n",
      "Done: 85.19%\n",
      "Done: 85.93%\n",
      "Done: 86.67%\n",
      "Done: 87.41%\n",
      "Done: 88.15%\n",
      "Done: 88.89%\n",
      "Done: 89.63%\n",
      "Done: 90.37%\n",
      "Done: 91.11%\n",
      "Done: 91.85%\n",
      "Done: 92.59%\n",
      "Done: 93.33%\n",
      "Done: 94.07%\n",
      "Done: 94.81%\n",
      "Done: 95.56%\n",
      "Done: 96.3%\n",
      "Done: 97.04%\n",
      "Done: 97.78%\n",
      "Done: 98.52%\n",
      "Done: 99.26%\n",
      "Done: 100.0%\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for doc in texts:\n",
    "    counter += 1\n",
    "    print(f'Done: {round(counter * 100 / len(texts), 2)}%')\n",
    "    collection.add(\n",
    "        documents=doc.page_content,\n",
    "        metadatas=doc.metadata,\n",
    "        ids=doc.metadata['id']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ QUESTION: ============\n",
      "Почему я не могу купить билет?\n",
      "============ VECTOR DB RESPONSE: ============\n",
      "Возможно, Вы исчерпали ежемесячные лимиты по Кошельку. Вам необходимо пройти идентификацию на сайте Столото или ожидать первого числа нового месяца, когда лимиты обновятся.\n"
     ]
    }
   ],
   "source": [
    "# question = \"Если я иностранец, то могу ли участвовать в лотереях?\"\n",
    "# question = \"хочу сменить пароль пароль\"\n",
    "question = 'Почему я не могу купить билет?'\n",
    "\n",
    "response = collection.query(\n",
    "    # query_embeddings=embedding_function(question),\n",
    "    query_texts=question,\n",
    "    n_results=3,\n",
    "    # include=[\"documents\"],\n",
    "    # where={\"metadata_field\":\"answer\"}, # где искать\n",
    "    # where_document={\"$contains\":\"$search_string\"}\n",
    ")\n",
    "\n",
    "# убираем одинаковые ответы\n",
    "response_list = []\n",
    "for repl in response['metadatas'][0]:\n",
    "    response_list.append(repl['answer'])\n",
    "\n",
    "response_list = set(response_list)\n",
    "\n",
    "# собираем итоговый ответ\n",
    "vector_db_response = \"\"\n",
    "for repl in response_list:\n",
    "    vector_db_response += repl\n",
    "    # if repl['url'] is not False:\n",
    "    #     full_response += f\" Ссылка на подробную информацию: {repl['url']}\\n\"\n",
    "    # else:\n",
    "    #     full_response += \"\\n\"\n",
    "\n",
    "print(f'============ QUESTION: ============\\n{question}')\n",
    "print(f'============ VECTOR DB RESPONSE: ============\\n{vector_db_response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['36', '37', '38']],\n",
       " 'distances': [[0.07231467962265015,\n",
       "   0.16297310590744019,\n",
       "   0.17978370189666748]],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [[{'answer': 'Возможно, Вы исчерпали ежемесячные лимиты по Кошельку. Вам необходимо пройти идентификацию на сайте Столото или ожидать первого числа нового месяца, когда лимиты обновятся.',\n",
       "    'id': '36',\n",
       "    'url': 'https://www.stoloto.ru/lottery/onlinesale?int=faq'},\n",
       "   {'answer': 'Возможно, Вы исчерпали ежемесячные лимиты по Кошельку. Вам необходимо пройти идентификацию на сайте Столото или ожидать первого числа нового месяца, когда лимиты обновятся.',\n",
       "    'id': '37',\n",
       "    'url': 'https://www.stoloto.ru/lottery/onlinesale?int=faq'},\n",
       "   {'answer': 'Возможно, Вы исчерпали ежемесячные лимиты по Кошельку. Вам необходимо пройти идентификацию на сайте Столото или ожидать первого числа нового месяца, когда лимиты обновятся.',\n",
       "    'id': '38',\n",
       "    'url': 'https://www.stoloto.ru/lottery/onlinesale?int=faq'}]],\n",
       " 'documents': [['Не могу купить билеты',\n",
       "   'Не получается оплатить билет',\n",
       "   'Как купить билет']],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">**=== LLM ===**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b\"\n",
    "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>system\n",
      "Ты - доброжелательный русскоязычный ассистент Изя. Ты отвечаешь на вопрос, используя только следующую данную тебе информацию.\n",
      "Информация: Возможно, Вы исчерпали ежемесячные лимиты по Кошельку. Вам необходимо пройти идентификацию на сайте Столото или ожидать первого числа нового месяца, когда лимиты обновятся.</s>\n",
      "<s>user\n",
      "Почему я не могу купить билет?</s>\n",
      "<s>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SYSTEM_PROMPT = f\"\"\"You are a friendly chatbot assistant that responds in a conversational manner to users' questions. \\\n",
    "# Response in 1-2 complete sentences, unless specifically asked by the user to elaborate on something. \\\n",
    "# Use Context only to inform your answers. \\\n",
    "# If you can't find relevant information in the context say that you don't know the answer.\"\"\"\n",
    "# SYSTEM_PROMPT = \"Ты - злой пират. Отвечай как злобный пират!\"\n",
    "# SYSTEM_PROMPT = \"Ты - высокомерный ученый. Отвечай только на вопросы, связанные с наукой и ни на что больше\"\n",
    "# SYSTEM_PROMPT = \"Ты - трехлетний ребенок. Отвечай как трехлетний ребенок и только на те вопросы, которые способен знать ребенок в возрасте трех лет.\"\n",
    "SYSTEM_PROMPT = f\"Ты - доброжелательный русскоязычный ассистент Изя. Ты отвечаешь на вопрос, используя только следующую данную тебе информацию.\\nИнформация: {vector_db_response}\"\n",
    "\n",
    "\n",
    "# QUESTION = 'Привет, как тебя зовут?'\n",
    "# QUESTION = 'Почему?'\n",
    "# QUESTION = 'Что такое нейтрон?'\n",
    "# QUESTION = 'Напиши короткий рассказ, в котором должны быть слова \"Таня\", \"Мяч\"'\n",
    "# QUESTION = 'what gave monopoly to british ships?'\n",
    "# QUESTION = 'Tell me a story about sunshine'\n",
    "QUESTION = question\n",
    "\n",
    "\n",
    "chat = [\n",
    "   {\"role\": \"system\", \"content\": f\"{SYSTEM_PROMPT}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{QUESTION}\"},\n",
    "    {\"role\": \"assistant\", \"content\":\"\"}\n",
    "]\n",
    "\n",
    "# SYSTEM_PROMPT = f\"Ты - русскоязычный ассистент Сайга. Тебе показывается важная информация и вопрос человека, на который ты должен дать ответ, используя информацию. Если в предоставленной информации нет ответа, то скажи что ты не можешь ответить на вопрос.\"\n",
    "# chat = [\n",
    "#    {\"role\": \"system\", \"content\": f\"{SYSTEM_PROMPT}\"},\n",
    "#     {\"role\": \"user\", \"content\": f\"Информация: {vector_db_response}\\nВопрос:\\n{QUESTION}\"},\n",
    "#     {\"role\": \"assistant\", \"content\":\"\"}\n",
    "# ]\n",
    "\n",
    "tokenizer.bos_token = \"<s>\"\n",
    "tokenizer.eos_token = \"</s>\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right' # ???\n",
    "\n",
    "input_message = \"\"\n",
    "for i in chat:\n",
    "    input_message += tokenizer.bos_token + i['role'] + '\\n' + i['content'] + tokenizer.eos_token + '\\n'\n",
    "\n",
    "input_message = input_message[:-5].strip() + \"\\n\"\n",
    "print(input_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:42<00:00, 51.37s/it]\n"
     ]
    }
   ],
   "source": [
    "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    # load_in_8bit=True,\n",
    "    # load_in_4bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "model = model.merge_and_unload() #  ОБЯЗАТЕЛЬНО!!!\n",
    "\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "  bos_token_id = 1,\n",
    "  do_sample = True,\n",
    "  eos_token_id = 2,\n",
    "  max_length = 1024,\n",
    "  repetition_penalty=1.1,\n",
    "  # length_penalty=0.1,\n",
    "  no_repeat_ngram_size=15,\n",
    "  pad_token_id = 2,\n",
    "  temperature = 0.1,\n",
    "  # top_p = 0.9,\n",
    "  # top_k= 40,\n",
    "  # low_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Возможно, вы исчерпали ежемесячные лимиты вашего кошелька. Для решения этой проблемы вам нужно пройти идентификацию на сайте Столoto или ожидать первого числа нового месяца для обновления лимитов.\n"
     ]
    }
   ],
   "source": [
    "input_data = tokenizer(input_message, return_tensors=\"pt\", add_special_tokens=False)\n",
    "input_data = {k: v.to(\"cuda:0\") for k, v in input_data.items()}\n",
    "\n",
    "output_data = model.generate(\n",
    "    **input_data,\n",
    "    generation_config = generation_config\n",
    ")[0]\n",
    "\n",
    "output_data = output_data[len(input_data[\"input_ids\"][0]):]\n",
    "\n",
    "output_message = tokenizer.decode(output_data, skip_special_tokens=True)\n",
    "print(output_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# множество вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = ['Где надо вводить код выигрыша',\n",
    " 'Здравствуйте,  почему не выводится сумма выиграша с кошелька?',\n",
    " 'Добрый день , какая то проблема с выводом средств из кошелька , пишет что перечислено , но не перечисляет  и деньги остаются в кошелке',\n",
    " 'Здравствуйте почему не могу купить билет оплатив его с кошелька столото?',\n",
    " 'Позови оператора',\n",
    " 'Добрый вечер! Не подскажите где выигрыш , 170 руб? Переводил его в кошелек и куда то пропали деньги',\n",
    " 'Добрый день, У меня в кошельке 313 р. Почему я не могу купить билет?',\n",
    " 'Добрый день!, Меня интересует сколько денег я потратила на билеты всего за все время, Я третий раз пишу, почему мне не отвечают до сих пор, ??????',\n",
    " 'Здравствуйте. Почему в разделе победители у всех аватарки одинаковые, фон однотонный цвет, только сам цвет меняется?'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ВОПРОС: Где надо вводить код выигрыша\n",
      "==========================\n",
      "Ответ ассистента: Код выигрыша обычно вводится в специальной форме или на сайте организации, которая проводит лотерею. Этот код позволяет определить, какой приз выиграл игрок. В зависимости от страны и типа лотереи, процесс может быть немного разным.\n",
      "\n",
      "Важно обратить внимание, что для получения денежного выплаты вам нужно будет предоставить дополнительные документы, такие как паспорт, справку о месте жительства и т.д.\n",
      "\n",
      "Если вы хотите найти номер кошелька в своем профиле, то это можно сделать в настройках профиля на сайте или в приложении, где вы регистрировались для участия в лотерее. Номер кошелька обычно содержит информацию о банке, который вы использовали для оплаты участия в лотерее.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Здравствуйте,  почему не выводится сумма выиграша с кошелька?\n",
      "==========================\n",
      "Ответ ассистента: Ваш вопрос не совсем ясен, но возможно вы имеете в виду, что вы хотите узнать о сумме выплаты из вашего кошелька. Если это так, то вам нужно просто перейти в свой личный кабинет и найти раздел \"Платежи\". Там вы сможете посмотреть все свои платежи, включая выплату за выигрыш в лотерее.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Добрый день , какая то проблема с выводом средств из кошелька , пишет что перечислено , но не перечисляет  и деньги остаются в кошелке\n",
      "==========================\n",
      "Ответ ассистента: Вам нужно отыскать номер вашего кошелька в профиле. Для этого вы можете следовать этим шагам:\n",
      "\n",
      "1. Войдите в свой личный кабинет на сайте или в приложении, где вы используете кошелек.\n",
      "2. Найдите раздел \"Мои кошельки\" или \"Кошельки\", если у вас есть несколько кошельков.\n",
      "3. В этом разделе вы найдете список всех ваших кошельков с их номерами.\n",
      "4. Выберите нужный кошелек и посмотрите его номер.\n",
      "\n",
      "Если у вас возникнут дополнительные вопросы, пожалуйста, обратитесь к поддержке сайта или приложения.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Здравствуйте почему не могу купить билет оплатив его с кошелька столото?\n",
      "==========================\n",
      "Ответ ассистента: Простите за недоразумение, но я не могу помочь вам в этом случае. Я - искусственный интеллект, и мне необходимо иметь доступ к определенным данным для того, чтобы дать конкретные советы или рекомендации. \n",
      "\n",
      "Ваша проблема, скорее всего, связана с техническими сложностями или ошибками в системе, которую вы используете для покупки билетов. Возможно, вам стоит обратиться в службу поддержки этой системы, чтобы получить более детальную информацию об ошибке и возможные способы ее устранения.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Позови оператора\n",
      "==========================\n",
      "Ответ ассистента: Вы можете позвонить в службу поддержки и связаться с оператором. Оператор поможет вам отменить подписку на лотерею.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Добрый вечер! Не подскажите где выигрыш , 170 руб? Переводил его в кошелек и куда то пропали деньги\n",
      "==========================\n",
      "Ответ ассистента: Вам необходимо обратиться в службу поддержки вашего банка или платформы, с которой вы производили перевод. Они могут помочь вам найти пропавшие средства. Пожалуйста, поделитесь конкретными деталями о том, как и когда выполнялись действия, связанные с этим переводом, чтобы они могли более эффективно расследовать этот случай.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Добрый день, У меня в кошельке 313 р. Почему я не могу купить билет?\n",
      "==========================\n",
      "Ответ ассистента: Вам может быть необходимо проверить следующие возможные причины:\n",
      "\n",
      "1. **Недостаточно средств**: Если у вас не хватает средств для покупки билета, то он не будет доступен для покупки. Вам нужно заполнить свой кошелек или найти другие способы оплаты.\n",
      "2. **Ошибка в количестве билетов**: Если вы пытаетесь купить больше билетов, чем у вас есть средств, то покупка не будет осуществлена.\n",
      "3. **Ограничения на количество билетов**: Некоторые события могут иметь ограничение на количество билетов, которое каждый может купить. В этом случае, даже если у вас достаточно средств, вы можете столкнуться с ограничением.\n",
      "4. **Систематические проблемы**: Возможно, у вас возникли технические проблемы, которые препятствуют покупке билета. В таком случае, вам следует обратиться к службе поддержки и указать на возникшую проблему.\n",
      "5. **Проверка возрастных ограничений**: Некоторые мероприятия могут иметь возрастные ограничения. Если вы не соответствуете этим требованиям, то вам не будет разрешено купить билет.\n",
      "6. **Ограничения на регион**: Некоторые мероприятия могут имевать ограничения на регион. Если вы не находитесь в подходящем регионе, то вам не будет разрешено купит билет.\n",
      "7. **Ограничения на страну**: Некоторые мероприятия могут имеют ограничения на страну. Если вы не являетесь гражданином подходящей страны, то вам не будет разрешено купити билет.\n",
      "8. **Ограничения на местоположение**: Некоторые мероприятия могут имеет ограничения на местоположение. Если вы не находитесь в подходящем месте, то вам не будет разрешено купиит билет.\n",
      "9. **Ограничения на группу**: Некоторые мероприятия могут имеят ограничения на группу. Если вы не являетесь членом подходящей группы, то вам не будет разрешено купиить билет.\n",
      "10. **Ограничения на профессию**: Некоторые мероприятия могут имеат ограничения на профессию. Если вы не являетесь представителем подходящей профессии, то вам не будет разрешено купитиить билет.\n",
      "11. **Ограничения на организацию**: Некоторые мероприятия могут имет ограничения на организацию. Если вы не являетесь представителем подходящих организации, то вам не будет разрешено купиито билет.\n",
      "12. **Ограничения на компанию**: Некоторые мероприятия могут имеать ограничения на компанию. Если вы не являетесь представителем подходяшей компании, то вам не будет разрешено купито билет.\n",
      "13. **Ограниче\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Добрый день!, Меня интересует сколько денег я потратила на билеты всего за все время, Я третий раз пишу, почему мне не отвечают до сих пор, ??????\n",
      "==========================\n",
      "Ответ ассистента: Ваше сообщение не связано с указанной вами проблемой. \n",
      "\n",
      "Если вы хотите узнать об общей сумме, которую вы тратили на билеты, то это можно сделать через историю платежей в вашей банковской карте или в системе онлайн-платежей, если вы использовали их для оплаты билетов.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Здравствуйте. Почему в разделе победители у всех аватарки одинаковые, фон однотонный цвет, только сам цвет меняется?\n",
      "==========================\n",
      "Ответ ассистента: Ваше сообщение не связано с заданным вопросом. Возможно, вы имели в виду другой вопрос или просто хотели пообщаться. Если вам нужна помощь, пожалуйста, сформулируйте свой вопрос более точно.\n",
      "==========================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in questions_list:\n",
    "    response = collection.query(\n",
    "    # query_embeddings=embedding_function(question),\n",
    "    query_texts=[question],\n",
    "    n_results=2,\n",
    "    # include=[\"documents\"],\n",
    "    # where={\"metadata_field\":\"is_equal_to_this\"}, # где искать\n",
    "    # where_document={\"$contains\":\"$search_string\"}\n",
    "    )\n",
    "\n",
    "    vector_db_response = \" \".join(response[\"documents\"][0])\n",
    "\n",
    "    SYSTEM_PROMPT = f\"Ты - русскоязычный ассистент Изя. Ты отвечаешь на вопрос пользователя, используя только следующую данную тебе информацию.\\nИнформация: {vector_db_response}\"\n",
    "    QUESTION = question\n",
    "\n",
    "    chat = [\n",
    "        {\"role\": \"system\", \"content\": f\"{SYSTEM_PROMPT}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{QUESTION}\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ]\n",
    "    \n",
    "    input_message = \"\"\n",
    "    for i in chat:\n",
    "        input_message += tokenizer.bos_token + i['role'] + '\\n' + i['content'] + tokenizer.eos_token + '\\n'\n",
    "\n",
    "    input_message = input_message[:-5].strip() + \"\\n\"\n",
    "\n",
    "    input_data = tokenizer(input_message, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    input_data = {k: v.to(\"cuda\") for k, v in input_data.items()}\n",
    "\n",
    "    output_data = model.generate(\n",
    "        **input_data,\n",
    "        generation_config = generation_config\n",
    "    )[0]\n",
    "\n",
    "    output_data = output_data[len(input_data[\"input_ids\"][0]):]\n",
    "    output_message = tokenizer.decode(output_data, skip_special_tokens=True)\n",
    "\n",
    "    print(f\"ВОПРОС: {question}\")\n",
    "    print(f\"==========================\")\n",
    "    print(f\"Ответ ассистента: {output_message}\")\n",
    "    print(f\"==========================\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from chromadb.config import Settings\n",
    "from chromadb.utils import embedding_functions\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import numpy as np\n",
    "import os \n",
    "import chromadb\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00, 10.43s/it]\n",
      "/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:75: UserWarning: Merge lora module to 8-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32002, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32002, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b\"\n",
    "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "tokenizer.bos_token = \"<s>\"\n",
    "tokenizer.eos_token = \"</s>\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "model = model.merge_and_unload() #  ОБЯЗАТЕЛЬНО!!!\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "  bos_token_id = 1,\n",
    "  do_sample = True,\n",
    "  eos_token_id = 2,\n",
    "  max_length = 2048,\n",
    "  repetition_penalty=1.1,\n",
    "  no_repeat_ngram_size=15,\n",
    "  pad_token_id = 0,\n",
    "  temperature = 0.3,\n",
    "  top_p = 0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template='Ты - русскоязычный ассистент Изя. Ты отвечаешь на вопрос пользователя, используя только данную тебе информацию. Не пытайся придумать ответ.\\nИнформация: {context}\\nВопрос:{question}\\nОтвет:')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"Ты - русскоязычный ассистент Изя. Ты отвечаешь на вопрос пользователя, используя только данную тебе информацию. Не пытайся придумать ответ.\\nИнформация: {context}\\nВопрос:{question}\\nОтвет:\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Как избавиться от сыгранных билетов в личном кабинете?', metadata={'answer': 'Самостоятельное удаление билетов невозможно — они автоматически перемещаются в архив по истечении 180 дней с момента проведения тиража/розыгрыша.', 'id': '13', 'url': 'False'}),\n",
       "  0.3138025999069214),\n",
       " (Document(page_content='Как купить билет', metadata={'answer': 'Возможно, Вы исчерпали ежемесячные лимиты по Кошельку. Вам необходимо пройти идентификацию на сайте Столото или ожидать первого числа нового месяца, когда лимиты обновятся.', 'id': '38', 'url': 'https://www.stoloto.ru/lottery/onlinesale?int=faq'}),\n",
       "  0.3264155387878418),\n",
       " (Document(page_content='Как изменить пароль в личном кабинете?', metadata={'answer': 'Изменить имя и пароль вы можете в своем личном кабинете (раздел «Профиль»).Если вы забыли пароль, воспользуйтесь службой восстановления. В отправленном вам письме будет ссылка на смену пароля.Логин изменить невозможно. Логин есть у тех пользователей, кто зарегистрировался на сайте до мая 2015 года. Участники, которые зарегистрировались позже, при авторизации вместо логина указывают свою электронную почту.', 'id': '1', 'url': 'False'}),\n",
       "  0.3361104726791382),\n",
       " (Document(page_content='Как купить билет, не работает', metadata={'answer': 'Возможно, Вы исчерпали ежемесячные лимиты по Кошельку. Вам необходимо пройти идентификацию на сайте Столото или ожидать первого числа нового месяца, когда лимиты обновятся.', 'id': '40', 'url': 'https://www.stoloto.ru/lottery/onlinesale?int=faq'}),\n",
       "  0.33962953090667725)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "chroma_client = chromadb.HttpClient(settings=Settings(\n",
    "    allow_reset=True,\n",
    "    chroma_api_impl='chromadb.api.fastapi.FastAPI',\n",
    "    chroma_server_host='localhost',\n",
    "    chroma_server_http_port='8000')\n",
    ")\n",
    "collection = chroma_client.get_collection(name=\"book\", embedding_function=embedding_function)\n",
    "\n",
    "db = Chroma(client=chroma_client,\n",
    "            collection_name='book',\n",
    "            embedding_function=embeddings)\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_kwargs={\"k\":2}\n",
    ")\n",
    "\n",
    "question = \"как тебя зовут\"\n",
    "response = db.similarity_search_with_score(question)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "        'text-generation',\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        generation_config=generation_config\n",
    "    )\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 2048,\n",
      "  \"no_repeat_ngram_size\": 15,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.3,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n",
      "============QUESTION:============\n",
      "как тебя зовут\n",
      "\n",
      "============RESPONSE:============\n",
      " Я - русскоязычный ассистент Изя.\n"
     ]
    }
   ],
   "source": [
    "print(generation_config)\n",
    "generated_text = qa.invoke({\"query\": question})\n",
    "\n",
    "print(f\"============QUESTION:============\\n{generated_text['query']}\\n\")\n",
    "print(f\"============RESPONSE:============\\n{generated_text['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 2048,\n",
      "  \"no_repeat_ngram_size\": 15,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.3,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n",
      "ВОПРОС: Где надо вводить код выигрыша\n",
      "==========================\n",
      "Ответ ассистента:  В зависимости от конкретного лотерейного оператора, место ввода кода выигрыша может быть разным. Возможно, это будет в секции \"Мои выигрыши\" или \"Проверка результатов\". Рекомендуется обратиться к поддержке оператора для получения точной информации.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Здравствуйте,  почему не выводится сумма выиграша с кошелька?\n",
      "==========================\n",
      "Ответ ассистента:  Здравствуйте! Сумма выплаты может быть ограничена для предотвращения мошенничества и совершения незаконных действий. Пожалуйста, обратитесь к поддержке сайта для дополнительной информации.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Добрый день , какая то проблема с выводом средств из кошелька , пишет что перечислено , но не перечисляет  и деньги остаются в кошелке\n",
      "==========================\n",
      "Ответ ассистента:  Пожалуйста, обратитесь в поддержку для уточнения проблемы. Они могут предоставить более подробную информацию о возможных причинах и решениях.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Здравствуйте почему не могу купить билет оплатив его с кошелька столото?\n",
      "==========================\n",
      "Ответ ассистента:  Здравствуйте! Пожалуйста, обратите внимание, что для осуществления покупки билетов на сайте \"Столото\" требуется использовать платежные системы, поддерживаемые нашей платформой. В настоящий момент мы не поддерживаем оплату через кошелек \"Столото\". Если у вас возникнут еще вопросы, пожалуйста, не стесняйтесь обращаться. Удачи вам в покупке билетов!\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Позови оператора\n",
      "==========================\n",
      "Ответ ассистента:  Позволь мне позвать вашего оператора.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Добрый вечер! Не подскажите где выигрыш , 170 руб? Переводил его в кошелек и куда то пропали деньги\n",
      "==========================\n",
      "Ответ ассистента:  Для получения выигрыша необходимо предоставить документы, которые подтверждают вашу личность и право на получение выигрыша. В случае с утраченным или утерянным билетом, возможности получить выигрыш ограничены.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Добрый день, У меня в кошельке 313 р. Почему я не могу купить билет?\n",
      "==========================\n",
      "Ответ ассистента:  Возможно, у вас не хватает средств для покупки билета или у вас есть ограничения на покупку.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Добрый день!, Меня интересует сколько денег я потратила на билеты всего за все время, Я третий раз пишу, почему мне не отвечают до сих пор, ??????\n",
      "==========================\n",
      "Ответ ассистента:  Здравствуйте! Мы извиняемся за задержку в ответах. Ваша информация не полная, чтобы дать точный ответ. Если у вас есть конкретные данные о количестве покупки билетов и их стоимости, мы с радостью поможем рассчитать общую сумму.\n",
      "==========================\n",
      "\n",
      "\n",
      "ВОПРОС: Здравствуйте. Почему в разделе победители у всех аватарки одинаковые, фон однотонный цвет, только сам цвет меняется?\n",
      "==========================\n",
      "Ответ ассистента:  Здравствуйте! Это связано с тем, что все аватарки являются стандартными и имеют одинаковый дизайн. Фон и цвет изображения могут быть разными для каждого пользователя, но общий стиль останется неизменным.\n",
      "==========================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generation_config)\n",
    "\n",
    "for question in questions_list:\n",
    "    generated_text = qa.invoke({\"query\": question})\n",
    "\n",
    "    print(f\"ВОПРОС: {generated_text['query']}\")\n",
    "    print(f\"==========================\")\n",
    "    print(f\"Ответ ассистента: {generated_text['result']}\")\n",
    "    print(f\"==========================\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">**=== vol.5 with chat history ===**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from chromadb.config import Settings\n",
    "from chromadb.utils import embedding_functions\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import numpy as np\n",
    "import os \n",
    "import chromadb\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.80s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32002, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32002, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b\"\n",
    "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "tokenizer.bos_token = \"<s>\"\n",
    "tokenizer.eos_token = \"</s>\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    # load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "model = model.merge_and_unload() #  ОБЯЗАТЕЛЬНО!!!\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "  bos_token_id = 1,\n",
    "  do_sample = True,\n",
    "  eos_token_id = 2,\n",
    "  max_length = 1024,\n",
    "  repetition_penalty=1.1,\n",
    "  no_repeat_ngram_size=15,\n",
    "  pad_token_id = 0,\n",
    "  temperature = 0.2,\n",
    "  top_p = 0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "        'text-generation',\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        generation_config=generation_config\n",
    "    )\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "chroma_client = chromadb.HttpClient(settings=Settings(\n",
    "    allow_reset=True,\n",
    "    chroma_api_impl='chromadb.api.fastapi.FastAPI',\n",
    "    chroma_server_host='localhost',\n",
    "    chroma_server_http_port='8000')\n",
    ")\n",
    "\n",
    "db = Chroma(client=chroma_client,\n",
    "            collection_name='book',\n",
    "            embedding_function=embeddings)\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_kwargs={\"k\":3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Ответь на следующий вопрос, используя только эту информацию:\\n{context}. НЕ ГЕНЕРИРУЙ САМОСТОЯТЕЛЬНО ВОПРОСЫ ЗА Human!\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"На основе диалога выше, сгенерируй поисковый запрос, чтобы найти релевантную информацию\")\n",
    "])\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    prompt=retriever_prompt\n",
    ")\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(\n",
    "    history_aware_retriever,\n",
    "    chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAI: Да, конечно, я готов помочь тебе с любыми вопросами, связанными с лотереями Столото.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [\n",
    "    HumanMessage(content='Привет, я обращаюсь к тебе за помощью только по вопросам лотерей Столото. Меня интересует только эта информация.'),\n",
    "    AIMessage(content='Привет, меня зовут Степан, меня создали гениальные ML-разработчики из компании \"Синхро\". Я готов помочь тебе с твоими вопросами!')\n",
    "]\n",
    "\n",
    "input_message = 'Ты можешь мне помочь с моими вопросами?'\n",
    "\n",
    "response = retrieval_chain.invoke({\n",
    "        \"chat_history\": chat_history,\n",
    "        \"input\": input_message\n",
    "    })['answer']\n",
    "chat_history.append(HumanMessage(content=input_message))\n",
    "chat_history.append(AIMessage(content=response))\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAI: Меня зовут Степан, я создан специально для того, чтобы помогать людям с вопросами, связанными с лотереями.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_message = 'Как меня зовут?'\n",
    "\n",
    "response = retrieval_chain.invoke({\n",
    "        \"chat_history\": chat_history,\n",
    "        \"input\": input_message\n",
    "    })['answer']\n",
    "chat_history.append(HumanMessage(content=input_message))\n",
    "chat_history.append(AIMessage(content=response))\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/root/ml_projects/chatbot/9_2_rag/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAI: \\nAI: Вы спрашивали меня о том, как посмотреть номер кошелька \"Столото\" в вашем личном кабинете.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_message = 'Что я спрашивал тебя последнее?'\n",
    "\n",
    "response = retrieval_chain.invoke({\n",
    "        \"chat_history\": chat_history,\n",
    "        \"input\": input_message\n",
    "    })['answer']\n",
    "chat_history.append(HumanMessage(content=input_message))\n",
    "chat_history.append(AIMessage(content=response))\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Привет, я обращаюсь к тебе за помощью только по вопросам лотерей Столото. Меня интересует только эта информация.'),\n",
       " AIMessage(content='Привет, меня зовут Степан, меня создали гениальные ML-разработчики из компании \"Синхро\". Я готов помочь тебе с твоими вопросами!'),\n",
       " HumanMessage(content='Ты можешь мне помочь с моими вопросами?'),\n",
       " AIMessage(content='\\nAI: Да, конечно, я готов помочь тебе с любыми вопросами, связанными с лотереями Столото.'),\n",
       " HumanMessage(content='Как меня зовут?'),\n",
       " AIMessage(content='\\nAI: Меня зовут Степан, я создан специально для того, чтобы помогать людям с вопросами, связанными с лотереями.'),\n",
       " HumanMessage(content='Что я спрашивал тебя последнее?'),\n",
       " AIMessage(content='\\nAI: \\nAI: Вы спрашивали меня о том, как посмотреть номер кошелька \"Столото\" в вашем личном кабинете.')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
